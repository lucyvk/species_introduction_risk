{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "import niche\n",
    "import csv\n",
    "import time\n",
    "out_location = \"paper_webs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating structures for web 0\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.8844833374023438\n",
      "generating structures for web 4\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.5103037357330322\n",
      "generating structures for web 8\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.145132303237915\n",
      "generating structures for web 10\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 4.281385898590088\n",
      "generating structures for web 13\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.467247724533081\n",
      "generating structures for web 14\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 4.038255214691162\n",
      "generating structures for web 16\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.929121494293213\n",
      "generating structures for web 18\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.3471741676330566\n",
      "generating structures for web 19\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.619952440261841\n",
      "generating structures for web 24\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.53544545173645\n",
      "generating structures for web 25\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.882028818130493\n",
      "generating structures for web 28\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.6194474697113037\n",
      "generating structures for web 34\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.7068681716918945\n",
      "generating structures for web 35\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.799805164337158\n",
      "generating structures for web 36\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.842832565307617\n",
      "generating structures for web 39\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.6380369663238525\n",
      "generating structures for web 40\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.7823479175567627\n",
      "generating structures for web 41\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.5508599281311035\n",
      "generating structures for web 43\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.5308423042297363\n",
      "generating structures for web 47\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.780681610107422\n",
      "generating structures for web 48\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.490633010864258\n",
      "generating structures for web 49\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.4725499153137207\n",
      "generating structures for web 50\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.486964702606201\n",
      "generating structures for web 55\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.282020092010498\n",
      "generating structures for web 57\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.4563937187194824\n",
      "generating structures for web 59\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.19085693359375\n",
      "generating structures for web 65\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.1108760833740234\n",
      "generating structures for web 66\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.1672699451446533\n",
      "generating structures for web 69\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.40836238861084\n",
      "generating structures for web 70\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.2409684658050537\n",
      "generating structures for web 74\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.4041333198547363\n",
      "generating structures for web 75\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.2395424842834473\n",
      "generating structures for web 76\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.1977555751800537\n",
      "generating structures for web 77\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.4793083667755127\n",
      "generating structures for web 87\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.2206971645355225\n",
      "generating structures for web 93\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.1231801509857178\n",
      "generating structures for web 99\n",
      "done invader 1\n",
      "done invader 2\n",
      "done both invaders\n",
      "overall time - 3.3182742595672607\n"
     ]
    }
   ],
   "source": [
    "# Link prediction - Generate new network structure with possible invaders\n",
    "# 45 structures produced with intermediate species (in_1) per web (scenario 1)\n",
    "# 45 structures produced with top predator species (in_2) per web (scenario 2)\n",
    "# 729 structures produced with both introduced species per web (scenario 3)\n",
    "\n",
    "webs1 = []\n",
    "fif_webs_file = open(f\"./{out_location}/over15_webs.txt\",'r')\n",
    "for row in fif_webs_file:\n",
    "    webs1.append(int(row))\n",
    "fif_webs_file.close()\n",
    "\n",
    "# intermediate species properties\n",
    "in_1_file = open(f\"./{out_location}/introduced_1.csv\",'r')\n",
    "in_1_reader = csv.reader(in_1_file)\n",
    "next(in_1_reader) # pass header\n",
    "in1s = []\n",
    "for row in in_1_reader:\n",
    "    in1s.append(row)\n",
    "    \n",
    "# top predator properties \n",
    "in_2_file = open(f\"./{out_location}/introduced_2.csv\",'r')\n",
    "in_2_reader = csv.reader(in_2_file)\n",
    "next(in_2_reader) # pass header\n",
    "in2s = []\n",
    "for row in in_2_reader:\n",
    "    in2s.append(row)\n",
    "\n",
    "# properties for introducing both species \n",
    "in_both_file = open(f\"./{out_location}/introduced_both.csv\",'r')\n",
    "in_both_reader = csv.reader(in_both_file)\n",
    "next(in_both_reader) # pass header\n",
    "inboths = []\n",
    "for row in in_both_reader:\n",
    "    inboths.append(row)\n",
    "\n",
    "in_1_file.close()\n",
    "in_2_file.close()\n",
    "in_both_file.close()\n",
    "\n",
    "for i in webs1:\n",
    "        \n",
    "    start = time.time()\n",
    "\n",
    "    print(f\"generating structures for web {i}\")\n",
    "\n",
    "    # get properties of current web \n",
    "    recipient_net,nis,ris,cis,b_curr = niche.read_web_from_file(f\"./{out_location}/web_{i}_2000\")\n",
    "\n",
    "    # output folder to save network structures shortly after invasion\n",
    "    if not os.path.exists(f\"./{out_location}/web_{i}_inv\"):\n",
    "        os.makedirs(f\"./{out_location}/web_{i}_inv\")\n",
    "\n",
    "    # add them for introduced species 1\n",
    "    if not os.path.exists(f\"./{out_location}/web_{i}_inv/one\"):\n",
    "        os.makedirs(f\"./{out_location}/web_{i}_inv/one\")\n",
    "    for row in in1s:\n",
    "        in_id = int(row[0])\n",
    "\n",
    "        nis[in_id] = float(row[1])\n",
    "        ris[in_id] = float(row[2])\n",
    "        cis[in_id] = float(row[3])\n",
    "        b_curr[in_id] = 0.75 # always introduce with biomass 0.75\n",
    "\n",
    "        # generate links\n",
    "        web_new = nx.DiGraph()\n",
    "        web_new.add_nodes_from(recipient_net.nodes())\n",
    "        web_new.add_node(in_id) # add introduced species node\n",
    "        web_new = niche.assign_links(web_new,cis,ris,nis) # re-assign links \n",
    "\n",
    "        # write the new network structure to file \n",
    "        where = f\"./{out_location}/web_{i}_inv/one/web_{i}_inv_{in_id}\"\n",
    "        niche.write_web_to_file(web_new,nis,ris,cis,b_curr,where)\n",
    "\n",
    "        # pop the added introduced species information from the dictionaries to reset for next introduction\n",
    "        # this is done so that we don't need to create new parameter objects for each introduction\n",
    "        nis.pop(in_id)\n",
    "        ris.pop(in_id)\n",
    "        cis.pop(in_id)\n",
    "        b_curr.pop(in_id)\n",
    "\n",
    "    print(\"done invader 1\")\n",
    "\n",
    "    # add them for introduced species 2\n",
    "    if not os.path.exists(f\"./{out_location}/web_{i}_inv/two\"):\n",
    "        os.makedirs(f\"./{out_location}/web_{i}_inv/two\")\n",
    "    for row in in2s:\n",
    "        in_id = int(row[0])\n",
    "\n",
    "        nis[in_id] = float(row[1])\n",
    "        ris[in_id] = float(row[2])\n",
    "        cis[in_id] = float(row[3])\n",
    "        b_curr[in_id] = 0.75 # always introduce with biomass 0.75\n",
    "\n",
    "        # generate links\n",
    "        web_new = nx.DiGraph()\n",
    "        web_new.add_nodes_from(recipient_net.nodes())\n",
    "        web_new.add_node(in_id) # add introduced species node\n",
    "        web_new = niche.assign_links(web_new,cis,ris,nis) # re-assign links \n",
    "\n",
    "        # write the new network structure to file \n",
    "        where = f\"./{out_location}/web_{i}_inv/two/web_{i}_inv_{in_id}\"\n",
    "        niche.write_web_to_file(web_new,nis,ris,cis,b_curr,where)\n",
    "\n",
    "        # pop the added introduced species information from the dictionaries to reset for next introduction\n",
    "        nis.pop(in_id)\n",
    "        ris.pop(in_id)\n",
    "        cis.pop(in_id)\n",
    "        b_curr.pop(in_id)\n",
    "\n",
    "    print(\"done invader 2\")\n",
    "\n",
    "    # add them for both introduced species\n",
    "    if not os.path.exists(f\"./{out_location}/web_{i}_inv/both\"):\n",
    "        os.makedirs(f\"./{out_location}/web_{i}_inv/both\")\n",
    "    for row in inboths:\n",
    "        in_id1 = int(row[0])\n",
    "        in_id2 = int(row[1])\n",
    "\n",
    "        # add parameters for both introduced species \n",
    "        nis[in_id1] = float(row[2])\n",
    "        nis[in_id2] = float(row[3])\n",
    "        ris[in_id1] = float(row[4])\n",
    "        ris[in_id2] = float(row[5])\n",
    "        cis[in_id1] = float(row[6])\n",
    "        cis[in_id2] = float(row[7])\n",
    "        b_curr[in_id1] = 0.75\n",
    "        b_curr[in_id2] = 0.75\n",
    "\n",
    "        # generate links\n",
    "        web_new = nx.DiGraph()\n",
    "        web_new.add_nodes_from(recipient_net.nodes())\n",
    "        web_new.add_node(in_id1) # add introduced species node 1 \n",
    "        web_new.add_node(in_id2) # add introduced species node 2\n",
    "        web_new = niche.assign_links(web_new,cis,ris,nis) # re-assign links \n",
    "\n",
    "        where = f\"./{out_location}/web_{i}_inv/both/web_{i}_inv_{in_id1}_{in_id2}\"\n",
    "        niche.write_web_to_file(web_new,nis,ris,cis,b_curr,where)\n",
    "\n",
    "        # pop the added introduced species information from the dictionaries to reset for next introduction\n",
    "        nis.pop(in_id1)\n",
    "        ris.pop(in_id1)\n",
    "        cis.pop(in_id1)\n",
    "        b_curr.pop(in_id1)\n",
    "\n",
    "        nis.pop(in_id2)\n",
    "        ris.pop(in_id2)\n",
    "        cis.pop(in_id2)\n",
    "        b_curr.pop(in_id2)\n",
    "\n",
    "    print(\"done both invaders\")\n",
    "    end = time.time()\n",
    "    print(f\"overall time - {end - start}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
